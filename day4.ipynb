{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60995166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbcfcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = test.load_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4d88a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65fd09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who won the prestigious IIOTY award in 2023?\n",
      "direct_fact\n",
      "Maxine Thompson won the prestigious Insurellm Innovator of the Year (IIOTY) award in 2023.\n",
      "['Maxine', 'Thompson', 'IIOTY']\n"
     ]
    }
   ],
   "source": [
    "example = tests[0]\n",
    "print(example.question)\n",
    "print(example.category)\n",
    "print(example.reference_answer)\n",
    "print(example.keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f058ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  \\n\\nspanning is when the answer is spread across different chunks, it is difficult for models to answer these questions\\nholistic when you know only when you have read lot of documents, llm struggles here\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count = Counter([t.category for t in tests])\n",
    "count\n",
    "\n",
    "'''  \n",
    "\n",
    "spanning is when the answer is spread across different chunks, it is difficult for models to answer these questions\n",
    "holistic when you know only when you have read lot of documents, llm struggles here\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b413b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.eval import evaluate_retrieval, evaluate_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daca435e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalEval(mrr=0.6666666666666666, ndcg=0.6399069297160626, keywords_found=2, total_keywords=3, keyword_coverage=66.66666666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_retrieval(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925b37d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval, answer, chunks = evaluate_answer(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01965312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerEval(feedback=\"The generated answer correctly identifies the winner's first name 'Maxine' and the award 'Insurellm Innovator of the Year' for 2023, aligning with the reference answer. However, it omits the full name 'Maxine Thompson', which is provided in the reference and specifies the recipient more precisely. It directly answers the question but could include the full name for completeness.\", accuracy=4.0, completeness=4.0, relevance=5.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd34561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer correctly identifies Maxine Thompson as the winner and specifies that the award is the Insurellm Innovator of the Year (IIOTY) for 2023, aligning precisely with the reference answer. It is accurate, complete, and directly responds to the question without extraneous information.\n",
      "5.0\n",
      "5.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(eval.feedback)\n",
    "print(eval.accuracy)\n",
    "print(eval.completeness)\n",
    "print(eval.relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e0cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
